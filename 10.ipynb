{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 10 (die letzte!)\n",
    "\n",
    "## Vorbereitung\n",
    "1. installiere [Theano](http://deeplearning.net/software/theano/)\n",
    "2. installiere [Keras](https://keras.io)\n",
    "3. stelle das Keras-Backend auf Theano um ([hier steht wie](https://keras.io/backend/))\n",
    "4. [teste Keras mit diesem Beispiel](https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py)\n",
    "5. [noch zu langsam?](http://www.chioka.in/why-is-keras-running-so-slow/)\n",
    "\n",
    "Jetzt bist Du ready for deep learning!\n",
    "\n",
    "## Daten holen\n",
    "Wir werden einen kleinen Bienentanz-Datensatz holen:\n",
    "\n",
    "1. installiere [Git LFS](https://git-lfs.github.com/)\n",
    "2. clone das [Daten-Repository](https://github.com/BioroboticsLab/WDD-Ground-Truth) (~ 2 GB)\n",
    "\n",
    "Die Daten sind in zwei Verzeichnis-Ebenen organisiert. Ebene eins korrespondiert zu einer Tageszeit und einer Kamera. Innerhalb eines solchen Verzeichnisses befinden sich Unterverzeichnisse, die zu einem detektierten Schwänzellauf korrespondieren. Die Bildausschnitte die eine schwänzelnde Biene zeigen sind im PNG-Format abgespeichert. \n",
    "\n",
    "````\n",
    "20160814_0935_1\n",
    "    0\n",
    "         20160814_0935_1_0.csv\n",
    "         gt.csv\n",
    "         image_000.png\n",
    "         image_001.png\n",
    "         ...\n",
    "         image_123.png\n",
    "    1\n",
    "         ...\n",
    "    2\n",
    "         ...\n",
    "```\n",
    "In der Datei \"gt.csv\" gibt es drei mögliche Character: 'j' für Tanz, 'n' für Kein-Tanz und 'v' für vielleicht (sollte aus dem Training exkludiert werden). \n",
    "\n",
    "## Convnet zur Erkennung von Bienentänzen\n",
    "Wir hatten in der Vorlesung besprochen, wie convnets auf Bilder strukturiert sind. Auch auch Bildersequenzen fester Länge können convnets angewandt werden. Baue, trainiere und evaluiere ein convnet auf den Bienentanzdaten! Nimm dabei als gegeben an, dass Sequenzen mit weniger als 20 Bildern keine Tänze enthalten. Wir würdest Du eine längere Bildsequenz behandeln um eine binäre Antwort (Tanz vs. Nicht-Tanz?\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
